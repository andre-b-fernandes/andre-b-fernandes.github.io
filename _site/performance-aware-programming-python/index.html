<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title></title>
    <script src="/assets/js/jquery/jquery-3.6.0.slim.min.js"></script>
    <script src="/assets/js/popperjs/popper-1.12.9.min.js"></script>
    <script src="/assets/js/bootstrap/bootstrap.min.js" ></script>
    <link rel="stylesheet" href="/assets/css/main.css">
    <meta name="viewport" content="width=device-width, height=device-height, initial-scale=1.0">
  </head>
  <body>
    <main>
	    <div class="row container-fluid">
	  <div class="col-lg-2 justify-content-center align-middle border-dark border-left border-right navbar-bg">
		<div class="card border-0 vscode-sidebar">
  <h4 class="card-title text-center"> André Fernandes</h4>
  <a href="/">
    <img class="card-img-top mx-auto" src="/assets/img/profile-pic.jpeg" alt="">
  </a>
  <div class="card-body">
    <p class="card-text font-weight-bold nav-indication"> Software Engineer - Data Scientist</p>
    <p class="card-text nav-indication"> FEUP, UPORTO, Portugal</p>
    <p class="card-text nav-link"><a href="https://github.com/andre-b-fernandes"> <i class="bi-github" role="img"></i> <span>andre-b-fernandes</span></a></p>
    <p class="card-text nav-link"><a href="httpsr//www.linkedin.com/in/af-fernandes"> <i class="bi-linkedin" role="img"></i> <span class="username">af-fernandes</span></a></p>
    
      <p class="card-text "></p>
        <a id="posts" class="navbar-link nav-link" href="/posts" role="tab">

		 <i class="bi bi-file-earmark-code-fill"></i>
		Posts 
	</a>
      
    
      <p class="card-text "></p>
        <a id="resume" class="navbar-link nav-link" href="/resume" role="tab">

		 <i class="bi bi-file-earmark-code-fill"></i>
		Resume 
	</a>
      
    
  </div>
</div>

	  </div>
	  <div class="col code-editor">
<div class="row">
		  <h1 class="page-heading mt-3 mb-4">Performance-Aware Programming &amp; Python: Optimizing Euclidean Distance Calculation</h1>
		</div>
<div class="row" style="display: block;">
		<h1 id="introduction">Introduction</h1>

<p>Performance-aware programming is the practice of writing code with an understanding of how it executes on the underlying hardware. While Python is known for its ease of use and readability, it is often criticized for being slow compared to lower-level languages like C. However, with the right optimization techniques, Python programs can be significantly accelerated.</p>

<p>In this blog post, we will explore CPU optimizations in Python and C by optimizing a simple but computationally expensive function: calculating the Euclidean distance between two matrices. The goal is to show how performance bottlenecks arise and how we can systematically improve execution time using different optimization strategies.</p>

<p>Example to Improve: Euclidean Distance Computation</p>

<p>The Euclidean distance between two matrices, Q (M x D) and X (N x D), is a fundamental operation in machine learning and data science applications. Given:</p>

<ul>
  <li>Q: A matrix of shape (M, D)</li>
  <li>X: A matrix of shape (N, D)</li>
</ul>

<p>The Euclidean distance between every pair of rows from Q and X is computed as:</p>

<p><img src="/assets/img/posts/performance-aware-programming-python/formula.png" alt="Euclidean Distance Formula"></p>

<p>I will start by a basic naive python implementation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">Q</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
    <span class="s">"""
    Compute the Euclidean distance between two matrices in a naive way.
    Pure python implementation

    Arguments:
        Q -- A matrix of shape (M, D)
        X -- A matrix of shape (N, D)
    Returns: A matrix of shape (M, N) where each element (i, j) is the Euclidean distance between Q[i] and X[j]
    """</span>   
    <span class="n">M</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Q has M rows, D features
</span>    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># X has N rows, D features
</span>
    <span class="c1"># Initialize distance matrix (M x N)
</span>    <span class="n">distances</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>  <span class="c1"># Iterate over each query vector
</span>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>  <span class="c1"># Iterate over each dataset vector
</span>            <span class="n">dist</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="p">):</span>  <span class="c1"># Compute squared distance
</span>                <span class="n">diff</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>
                <span class="n">dist</span> <span class="o">+=</span> <span class="n">diff</span> <span class="o">*</span> <span class="n">diff</span>  <span class="c1"># Squaring each difference
</span>            <span class="n">distances</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>  <span class="c1"># Compute final Euclidean distance
</span>    <span class="k">return</span> <span class="n">distances</span>
</code></pre></div></div>

<h1 id="waste-understanding-pythons-cpu-overhead">Waste: Understanding Python’s CPU Overhead</h1>

<p>A CPU executes a sequence of instructions that perform computations. For Euclidean distance calculations, relevant instructions include:</p>

<p>Load: Fetching matrix values from memory.</p>

<ul>
  <li>Subtract: Computing the difference between elements.</li>
  <li>Multiply: Squaring the differences.</li>
  <li>Sum: Accumulating the squared differences.</li>
  <li>Square Root: Finalizing the Euclidean distance calculation.</li>
</ul>

<p>In an optimized language like C, these operations translate directly into efficient machine instructions. However, in Python, the execution path is far more complex.
Example of x86_64 architecture:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>int a = 0;
int b = 2;
a+=b;
—-----------------------------
mov eax, [var1] ; Load var1 into eax
mov ebx, [var2] ; Load var2 into ebx 
add eax, ebx ; Add eax with ebx; store in eax
</code></pre></div></div>

<h2 id="python-execution-from-function-call-to-machine-code">Python Execution: From Function Call to Machine Code</h2>

<p>When executing a function in Python, the following steps occur:</p>

<ol>
  <li>
<strong>Python Function Call</strong>: The interpreter receives the function call.</li>
  <li>
<strong>Python Interpreter Execution</strong>: The function is parsed and converted into bytecode.</li>
  <li>
<strong>Bytecode Interpretation</strong>: CPython reads and interprets the bytecode.</li>
  <li>
<strong>Assembler and Machine Code Execution</strong>: The CPU eventually processes low-level instructions derived from Python’s high-level operations.</li>
</ol>

<p>Each of these steps introduces overhead, making Python significantly slower than compiled languages.</p>

<h2 id="unnecessary-cpu-cycles-in-python">Unnecessary CPU cycles in Python</h2>

<p>Python wastes CPU cycles with operations unrelated to actual Euclidean distance computation, such as:</p>

<ul>
  <li>
<strong>Dynamic Type Checking</strong>: Every operation involves type checks.</li>
  <li>
<strong>Reference Counting for Memory Management</strong>: Objects are tracked, leading to frequent memory overhead.</li>
  <li>
<strong>Interpreter Overhead</strong>: The Python runtime manages function calls, loops, and memory allocation dynamically.</li>
</ul>

<p>Because of these inefficiencies, raw Python implementations of mathematical computations can be orders of magnitude slower than optimized C or NumPy implementations.</p>

<p>Example of disassembled python code using the dis module in the <code class="language-plaintext highlighter-rouge">euclidean_distance</code> function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">dis</span> <span class="kn">import</span> <span class="n">dis</span><span class="p">;</span>
<span class="n">dis</span><span class="p">(</span><span class="n">naive_euclidean_distance</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 24         266 LOAD_FAST                0 (Q)  // Push to stack
            268 LOAD_FAST                5 (i)  // Push to stack
            270 BINARY_SUBSCR                   // Pop two items from the stack, subscript them (Q[i]), and push the result
            280 LOAD_FAST                8 (k) // Push to stack
            282 BINARY_SUBSCR                   // Pop two items from the stack, subscript them (Q[i][k]), and push the result
            292 LOAD_FAST                1 (X) // Push to stack
            294 LOAD_FAST                6 (j) // Push to stack
            296 BINARY_SUBSCR                   // Pop two items from the stack, subscript them (X[j]), and push the result
            306 LOAD_FAST                8 (k) // Push to stack
            308 BINARY_SUBSCR                   // Pop two items from the stack, subscript them (X[j][k]), and push the result
            318 BINARY_OP               10 (-)  // Pop two items from the stack, subtract them, and push the result
            322 STORE_FAST               9 (diff) // Store the result in a variable
</code></pre></div></div>

<h2 id="using-numba-for-just-in-time-compilation">Using Numba for Just-In-Time Compilation</h2>

<p>An alternative to rewriting in C is using Numba, a Just-In-Time (JIT) compiler that translates Python code into optimized machine code using LLVM. Unlike CPython’s bytecode interpretation, Numba compiles the function at runtime and injects machine code into memory for execution.</p>

<p>A simple Numba-optimized implementation:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>

<span class="o">@</span><span class="n">njit</span>
<span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">Q</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
    <span class="s">"""Computes Euclidean distance using a cache-friendly approach in pure Python"""</span>
    <span class="n">M</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="n">Q_sq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">([</span><span class="n">q</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="p">)])</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">Q</span><span class="p">]</span>
    <span class="n">X_sq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="p">)])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>
    <span class="c1"># Transpose X for better cache locality
</span>    <span class="n">X_T</span> <span class="o">=</span> <span class="p">[[</span><span class="n">X</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">d</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="p">)]</span>
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">dot_product</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">d</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_T</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="p">)])</span>
            <span class="n">distances</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Q_sq</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dot_product</span> <span class="o">+</span> <span class="n">X_sq</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">distances</span>
</code></pre></div></div>

<p><strong>Why Numba Runs Faster?</strong></p>

<ul>
  <li>
<strong>JIT Compilation</strong>: Translates Python functions into fast machine code at runtime.</li>
  <li>
<strong>LLVM Optimization</strong>: Uses LLVM to optimize loops and memory access.</li>
  <li>
<strong>Bypasses CPython Overhead</strong>: Avoids bytecode interpretation, reducing waste.</li>
</ul>

<p>Minimal Code Changes: Requires only a decorator (@jit) to accelerate performance.</p>

<h2 id="using-a-c-shared-object-from-ctypes">Using a C shared object from ctypes</h2>

<p>To overcome Python’s overhead, we can implement the same Euclidean distance function in C. Unlike Python, C is a compiled language that translates directly to efficient machine code, avoiding the performance bottlenecks introduced by Python’s dynamic nature.</p>

<p>A simple C implementation of Euclidean distance computation:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;math.h&gt;
</span>
<span class="c1">// Function to compute pairwise Euclidean distance</span>
<span class="kt">void</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">Q</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">distances</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">D</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Iterate over all pairs of points</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">float</span> <span class="n">sum_sq</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
            <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">D</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
	 	<span class="c1">// We access Q and X in a row-major order by computing the index</span>
		<span class="c1">// as i * D + k and j * D + k respectively.</span>
                <span class="kt">float</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
                <span class="n">sum_sq</span> <span class="o">+=</span> <span class="n">diff</span> <span class="o">*</span> <span class="n">diff</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="n">distances</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">sum_sq</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In order to call it from python we can use the ctypes module:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">ctypes</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load the compiled C shared library
</span><span class="n">lib</span> <span class="o">=</span> <span class="n">ctypes</span><span class="p">.</span><span class="n">CDLL</span><span class="p">(</span><span class="s">"./naive.so"</span><span class="p">)</span>  <span class="c1"># Use ".dll" on Windows
</span>
<span class="c1"># Define function prototype: void euclidean_distance(float*, float*, float*, int, int, int)
</span><span class="n">lib</span><span class="p">.</span><span class="n">euclidean_distance</span><span class="p">.</span><span class="n">argtypes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ctypes</span><span class="p">.</span><span class="n">POINTER</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">c_float</span><span class="p">),</span>  <span class="c1"># Q
</span>    <span class="n">ctypes</span><span class="p">.</span><span class="n">POINTER</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">c_float</span><span class="p">),</span>  <span class="c1"># X
</span>    <span class="n">ctypes</span><span class="p">.</span><span class="n">POINTER</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">c_float</span><span class="p">),</span>  <span class="c1"># D_matrix
</span>    <span class="n">ctypes</span><span class="p">.</span><span class="n">c_int</span><span class="p">,</span>  <span class="c1"># M
</span>    <span class="n">ctypes</span><span class="p">.</span><span class="n">c_int</span><span class="p">,</span>  <span class="c1"># N
</span>    <span class="n">ctypes</span><span class="p">.</span><span class="n">c_int</span>   <span class="c1"># D
</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">Q</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="s">"""Call the C function for Euclidean distance computation"""</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Flatten NumPy arrays to 1D C-compatible arrays
</span>    <span class="n">q_flat</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">x_flat</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Convert to C pointers
</span>    <span class="n">q_ptr</span> <span class="o">=</span> <span class="n">q_flat</span><span class="p">.</span><span class="n">ctypes</span><span class="p">.</span><span class="n">data_as</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">POINTER</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">c_float</span><span class="p">))</span>
    <span class="n">x_ptr</span> <span class="o">=</span> <span class="n">x_flat</span><span class="p">.</span><span class="n">ctypes</span><span class="p">.</span><span class="n">data_as</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">POINTER</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">c_float</span><span class="p">))</span>
    <span class="n">d_ptr</span> <span class="o">=</span> <span class="n">distances</span><span class="p">.</span><span class="n">ctypes</span><span class="p">.</span><span class="n">data_as</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">POINTER</span><span class="p">(</span><span class="n">ctypes</span><span class="p">.</span><span class="n">c_float</span><span class="p">))</span>

    <span class="c1"># Call the C function
</span>    <span class="n">lib</span><span class="p">.</span><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">q_ptr</span><span class="p">,</span> <span class="n">x_ptr</span><span class="p">,</span> <span class="n">d_ptr</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distances</span>
</code></pre></div></div>

<ul>
  <li>No Interpreter Overhead: The compiled C code runs directly on the CPU.</li>
  <li>Efficient Memory Management: C operates on raw arrays with minimal overhead.</li>
</ul>

<h1 id="instruction-level-parallelism">Instruction-Level Parallelism</h1>

<p>Modern CPUs have multiple execution pipelines, allowing them to process multiple instructions in parallel. However, naive implementations do not fully utilize this capability.</p>

<p>Challenges in Parallel Execution</p>

<ul>
  <li>
<strong>Pipeline Dependency</strong>: The instruction pipeline can only compute the next value of the sum if the current one has been completed.</li>
  <li>
<strong>Missed Opportunities for Optimization</strong>: The sum operation does not take advantage of the commutative property - the order of addition does not matter for the addition operation.</li>
</ul>

<p>Generated instructions in Arm A64 (M1 chip) for the inner loop of the C implementation:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0000000000003ee4	ldr	x8, [sp, #0x38]
0000000000003ee8	ldr	w9, [sp, #0x18]
0000000000003eec	ldr	w10, [sp, #0x1c]
0000000000003ef0	mul	w9, w9, w10
0000000000003ef4	ldr	w10, [sp, #0xc]
0000000000003ef8	add	w9, w9, w10
0000000000003efc	ldr	s0, [x8, w9, sxtw #2]
0000000000003f00	ldr	x8, [sp, #0x30]
0000000000003f04	ldr	w9, [sp, #0x14]
0000000000003f08	ldr	w10, [sp, #0x1c]
0000000000003f0c	mul	w9, w9, w10
0000000000003f10	ldr	w10, [sp, #0xc]
0000000000003f14	add	w9, w9, w10
0000000000003f18	ldr	s1, [x8, w9, sxtw #2]
0000000000003f1c	fsub	s0, s0, s1
0000000000003f20	str	s0, [sp, #0x8]
0000000000003f24	ldr	s0, [sp, #0x8]
0000000000003f28	ldr	s1, [sp, #0x8]
0000000000003f2c	ldr	s2, [sp, #0x10]
0000000000003f30	fmadd	s0, s0, s1, s2 // -&gt; Only one fused multiply-add instruction per cycle
0000000000003f34	str	s0, [sp, #0x10]
0000000000003f38	b	0x3f3c
0000000000003f3c	ldr	w8, [sp, #0xc]
0000000000003f40	add	w8, w8, #0x1
0000000000003f44	str	w8, [sp, #0xc]
0000000000003f48	b	0x3ecc
0000000000003f4c	ldr	s0, [sp, #0x10]
0000000000003f50	fcvt	d0, s0
0000000000003f54	fsqrt	d0, d0
</code></pre></div></div>

<h2 id="loop-unrolling">Loop unrolling</h2>

<p>By unrolling the loop, we can increase the number of instructions executed per iteration, allowing the CPU to better utilize its execution pipelines.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;math.h&gt;
</span>
<span class="cp">#define UNROLL_FACTOR 4
</span>
<span class="kt">void</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">Q</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">distances</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">D</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="kt">float</span> <span class="n">sum_sq</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
            <span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
            
            <span class="c1">// Unrolled loop</span>
            <span class="k">for</span> <span class="p">(;</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">UNROLL_FACTOR</span><span class="p">;</span> <span class="n">k</span> <span class="o">+=</span> <span class="n">UNROLL_FACTOR</span><span class="p">)</span> <span class="p">{</span>
                <span class="kt">float</span> <span class="n">diff1</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
                <span class="kt">float</span> <span class="n">diff2</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
                <span class="kt">float</span> <span class="n">diff3</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">];</span>
                <span class="kt">float</span> <span class="n">diff4</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">3</span><span class="p">];</span>
                <span class="n">sum_sq</span> <span class="o">+=</span> <span class="n">diff1</span> <span class="o">*</span> <span class="n">diff1</span> <span class="o">+</span> <span class="n">diff2</span> <span class="o">*</span> <span class="n">diff2</span> <span class="o">+</span> <span class="n">diff3</span> <span class="o">*</span> <span class="n">diff3</span> <span class="o">+</span> <span class="n">diff4</span> <span class="o">*</span> <span class="n">diff4</span><span class="p">;</span>
            <span class="p">}</span>
            
            <span class="c1">// Handle remaining elements</span>
            <span class="k">for</span> <span class="p">(;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">D</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="kt">float</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
                <span class="n">sum_sq</span> <span class="o">+=</span> <span class="n">diff</span> <span class="o">*</span> <span class="n">diff</span><span class="p">;</span>
            <span class="p">}</span>
            
            <span class="n">distances</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">sum_sq</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Let’s take a look now at the generated instructions for the inner loop:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0000000000003e74	str	s0, [sp, #0xc] // Storing in #0xc diff4.
0000000000003e78	ldr	s0, [sp, #0x18] // loading diff2 into s0
0000000000003e7c	ldr	s1, [sp, #0x18] // loading diff2 into s1
0000000000003e80	ldr	s2, [sp, #0x14] // loading diff1 into s2
0000000000003e84	ldr	s3, [sp, #0x14] // loading diff1 into s3
0000000000003e88	fmul	s2, s2, s3 // Multiplying diff1 * diff1
0000000000003e8c	fmadd	s2, s0, s1, s2 // Adding diff2 * diff2 to the previous result
0000000000003e90	ldr	s0, [sp, #0x10] // loading diff3 into s0
0000000000003e94	ldr	s1, [sp, #0x10] // loading diff3 into s1
0000000000003e98	fmadd	s2, s0, s1, s2 // Adding diff3 * diff3 to the previous result
0000000000003e9c	ldr	s0, [sp, #0xc] // loading diff4 into s0
0000000000003ea0	ldr	s1, [sp, #0xc] // loading diff4 into s1
0000000000003ea4	fmadd	s1, s0, s1, s2 // Adding diff4 * diff4 to the previous result
</code></pre></div></div>

<p>It now generates more instructions per iteration, allowing the CPU to better utilize its execution pipelines.</p>

<h1 id="cpu-caching">CPU Caching</h1>

<p>Efficient memory access is crucial for high-performance computing. Modern CPUs rely on multi-level caches to speed up memory access, but poor memory access patterns can lead to frequent cache misses and slow down computation.</p>

<h2 id="understanding-cpu-caches">Understanding CPU Caches</h2>

<ul>
  <li>
<strong>Cache Lines</strong>: Data from RAM is loaded into the CPU cache in blocks called cache lines, typically 64 bytes in size.</li>
  <li>
<strong>Cache Hierarchy</strong>: CPUs have multiple levels of cache (L1, L2, L3) that are much faster than RAM.
    <ul>
      <li>L1 Cache (Fastest, Smallest)
        <ul>
          <li>
<strong>Size</strong>: Typically 32KB to 128KB per core</li>
          <li>
<strong>Latency</strong>: <em>~3-5</em> CPU cycles</li>
        </ul>
      </li>
      <li>L2 Cache (Larger, Slightly Slower)
        <ul>
          <li>
<strong>Size</strong>: Typically 256KB to 2MB per core</li>
          <li>
<strong>Latency</strong>: <em>~10</em> CPU cycles</li>
        </ul>
      </li>
      <li>L3 Cache (Largest, Shared Across Cores)
        <ul>
          <li>
<strong>Size</strong>: Typically 4MB to 64MB shared across all cores</li>
          <li>
<strong>Latency</strong>: <em>~30-50</em> CPU cycles
RAM (Slowest, Largest)</li>
          <li>
<strong>Latency</strong>: <em>~100+</em> CPU cycles</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<strong>Cache Locality</strong>: Accessing nearby memory locations increases the likelihood of cache hits.</li>
  <li>
<strong>Cache Evictions</strong>::  When new data is loaded and there isn’t enough space in the cache, old data gets evicted.</li>
</ul>

<p>Modern CPUs have hardware prefetchers that try to predict memory access patterns and load data into cache before it is needed. Efficient memory access should follow predictable patterns that align with cache prefetching.
However, accessing data inefficiently can lead to performance issues:</p>

<p>To optimize performance:</p>

<p><strong>Access Memory Sequentially</strong>: Iterating over contiguous memory locations minimizes cache misses.
<strong>Structure Data for Locality</strong>: Store data in a way that maximizes reuse before eviction.
<strong>Use Blocking Techniques</strong>: Process data in small blocks that fit within cache lines to reduce cache thrashing.
By optimizing memory access patterns, we can significantly speed up our Euclidean distance computations and take full advantage of modern CPU architectures.</p>

<h2 id="our-issue">Our issue</h2>

<p>In our Euclidean distance computation, we compute distances between rows of matrices <code class="language-plaintext highlighter-rouge">Q (M × D)</code> and <code class="language-plaintext highlighter-rouge">X (N × D)</code>.
A naive implementation accesses <code class="language-plaintext highlighter-rouge">X[j, k]</code> repeatedly for each element in Q, which leads to poor cache utilization since not the entire X matrix migh fit in the cache.
Each iteration accesses a new row of X, which may cause cache eviction.
Fetching <code class="language-plaintext highlighter-rouge">X[j, k]</code>  again requires reloading it from RAM, adding significant latency.
This leads to thrashing, where useful data is frequently replaced before it can be reused.</p>

<h3 id="solution-blocking">Solution: Blocking</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">Q</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">distances</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">D</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j_block</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j_block</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">j_block</span> <span class="o">+=</span> <span class="n">B</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// Process X in blocks</span>
        <span class="kt">int</span> <span class="n">j_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">j_block</span> <span class="o">+</span> <span class="n">B</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span> <span class="o">?</span> <span class="p">(</span><span class="n">j_block</span> <span class="o">+</span> <span class="n">B</span><span class="p">)</span> <span class="o">:</span> <span class="n">N</span><span class="p">;</span>  <span class="c1">// Ensure last block fits</span>
	    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">j_block</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">j_end</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// Iterate within block</span>
		    <span class="kt">float</span> <span class="n">sum_sq</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
		    <span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
		    
		    <span class="c1">// Unrolled loop</span>
		    <span class="k">for</span> <span class="p">(;</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">UNROLL_FACTOR</span><span class="p">;</span> <span class="n">k</span> <span class="o">+=</span> <span class="n">UNROLL_FACTOR</span><span class="p">)</span> <span class="p">{</span>
			<span class="kt">float</span> <span class="n">diff1</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
			<span class="kt">float</span> <span class="n">diff2</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
			<span class="kt">float</span> <span class="n">diff3</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">];</span>
			<span class="kt">float</span> <span class="n">diff4</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">3</span><span class="p">];</span>
			<span class="n">sum_sq</span> <span class="o">+=</span> <span class="n">diff1</span> <span class="o">*</span> <span class="n">diff1</span> <span class="o">+</span> <span class="n">diff2</span> <span class="o">*</span> <span class="n">diff2</span> <span class="o">+</span> <span class="n">diff3</span> <span class="o">*</span> <span class="n">diff3</span> <span class="o">+</span> <span class="n">diff4</span> <span class="o">*</span> <span class="n">diff4</span><span class="p">;</span>
		    <span class="p">}</span>
		    
		    <span class="c1">// Handle remaining elements</span>
		    <span class="k">for</span> <span class="p">(;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">D</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
			<span class="kt">float</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
			<span class="n">sum_sq</span> <span class="o">+=</span> <span class="n">diff</span> <span class="o">*</span> <span class="n">diff</span><span class="p">;</span>
		    <span class="p">}</span>
		    
		    <span class="n">distances</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">sum_sq</span><span class="p">);</span>
		<span class="p">}</span>
	    <span class="p">}</span>
	<span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now we process X in blocks of size B, ensuring that each block fits within the cache.
The next block will only start once the current block is finished being used for all elements in Q.</p>

<h1 id="simd-vectorization">SIMD Vectorization</h1>

<p>To further improve performance, we can use Single Instruction, Multiple Data (SIMD), which allows multiple computations to be executed in parallel using special vector instructions.</p>

<h2 id="understanding-cpu-registers">Understanding CPU Registers</h2>

<p>Registers are small, ultra-fast memory locations inside the processor that store:</p>
<ul>
  <li>Operands and results of operations</li>
  <li>Memory addresses during execution</li>
  <li>Control information for execution flow</li>
</ul>

<p>Types of registers include:</p>

<ul>
  <li>General-purpose registers (store intermediate values)</li>
  <li>Control registers (manage execution state)</li>
  <li>Instruction pointer registers (track execution position)</li>
  <li>Flag registers (store condition codes)</li>
</ul>

<h2 id="simd-processing-multiple-values-at-once">SIMD: Processing Multiple Values at Once</h2>

<p>Normally, if we wish to operate on multiple operands, we require separate instructions for each operation. SIMD allows a single instruction to perform the same operation on multiple values simultaneously by using larger registers(vector registers) designed for parallel execution.
SIMD Extensions: NEON (ARM) and SSE (x86)
Most modern CPUs include SIMD extensions:</p>

<ul>
  <li>ARM (Apple M1, ARM64): Uses NEON instructions for vectorized computation.</li>
  <li>x86 (Intel, AMD): Uses the SSE (Streaming SIMD Extensions) and AVX (Advanced Vector Extensions) instruction sets:
    <ul>
      <li>SSE2, SSE3, SSE4: Earlier SIMD instruction sets for floating-point and integer operations.</li>
      <li>AVX, AVX2: Wider registers (256-bit) for more parallelism.</li>
      <li>AVX-512: Newer CPUs support 512-bit registers for even higher throughput.</li>
    </ul>
  </li>
</ul>

<h2 id="leveraging-simd-for-euclidean-distance-computation">Leveraging SIMD for Euclidean Distance Computation</h2>

<p>By using SIMD, we can:</p>
<ul>
  <li>Load multiple floating-point values into a single register.</li>
  <li>Perform parallel operations on multiple data points in one instruction.</li>
  <li>Reduce loop iterations and instruction count, improving execution efficiency.</li>
</ul>

<p>Using optimized libraries like NumPy (which internally uses SIMD) or writing explicit vectorized code with compiler intrinsics can drastically improve performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">Q</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="s">"""
    Compute the Euclidean distance between two matrices using numpy.
    Pure numpy implementation

    Arguments:
        Q -- A matrix of shape (M, D)
        X -- A matrix of shape (N, D)
    Returns: A matrix of shape (M, N) where each element (i, j) is the Euclidean distance between Q[i] and X[j]
    """</span>   
    <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Q</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distances</span>
</code></pre></div></div>

<h3 id="vector-intrinsics-in-c">Vector intrinsics in C</h3>

<blockquote>
  <p><img class="emoji" title=":warning:" alt=":warning:" src="https://github.githubassets.com/images/icons/emoji/unicode/26a0.png" height="20" width="20"> <strong>When running on MACOS</strong>: The SSE intrinsics are not available on macOS, so we need to use the <code class="language-plaintext highlighter-rouge">sse2neon.h</code> header file to emulate the SSE intrinsics using NEON intrinsics.</p>
</blockquote>

<p>Below we can see the optimized C implementation using SIMD intrinsics:</p>
<ol>
  <li>Setting the sum vector to zero.</li>
  <li>Loading 4 elements at a time from Q and X.</li>
  <li>Subtracting the elements.</li>
  <li>Squaring the differences.</li>
  <li>Reducing the 4 floats to 1.</li>
  <li>Handling the remaining elements.</li>
</ol>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// SSE intrinsics</span>
<span class="c1">// 4 for SSE, 8 for AVX</span>
<span class="cp">#ifdef __x86_64__
</span>   <span class="cp">#include &lt;immintrin.h&gt;
#else  	
</span>  <span class="cp">#include "sse2neon.h"
#endif
</span><span class="c1">// SIMD-optimized Euclidean distance function</span>
<span class="kt">void</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">Q</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">distances</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">D</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">__m128</span> <span class="n">sum_vec</span> <span class="o">=</span> <span class="n">_mm_setzero_ps</span><span class="p">();</span>  <span class="c1">// Initialize SIMD sum register to 0</span>

            <span class="kt">int</span> <span class="n">k</span><span class="p">;</span>
	    <span class="kt">int</span> <span class="n">block_size</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">;</span> <span class="n">k</span> <span class="o">+=</span> <span class="n">block_size</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// Process 4 elements at a time</span>
                <span class="n">__m128</span> <span class="n">q_vec</span> <span class="o">=</span> <span class="n">_mm_loadu_ps</span><span class="p">(</span><span class="o">&amp;</span><span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]);</span>
                <span class="n">__m128</span> <span class="n">x_vec</span> <span class="o">=</span> <span class="n">_mm_loadu_ps</span><span class="p">(</span><span class="o">&amp;</span><span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]);</span>
                <span class="n">__m128</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">_mm_sub_ps</span><span class="p">(</span><span class="n">q_vec</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">);</span>
                <span class="n">__m128</span> <span class="n">squared</span> <span class="o">=</span> <span class="n">_mm_mul_ps</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">diff</span><span class="p">);</span>
                <span class="n">sum_vec</span> <span class="o">=</span> <span class="n">_mm_add_ps</span><span class="p">(</span><span class="n">sum_vec</span><span class="p">,</span> <span class="n">squared</span><span class="p">);</span>
            <span class="p">}</span>

            <span class="c1">// Horizontal sum of sum_vec (reduces 4 floats to 1)</span>
            <span class="n">__m128</span> <span class="n">temp</span> <span class="o">=</span> <span class="n">_mm_add_ps</span><span class="p">(</span><span class="n">sum_vec</span><span class="p">,</span> <span class="n">_mm_movehl_ps</span><span class="p">(</span><span class="n">sum_vec</span><span class="p">,</span> <span class="n">sum_vec</span><span class="p">));</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="n">_mm_add_ss</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="n">_mm_shuffle_ps</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="mi">1</span><span class="p">));</span>
            <span class="kt">float</span> <span class="n">sum</span> <span class="o">=</span> <span class="n">_mm_cvtss_f32</span><span class="p">(</span><span class="n">temp</span><span class="p">);</span>  <span class="c1">// Extract final sum</span>

            <span class="c1">// Handle remaining elements (if D is not a multiple of 4)</span>
            <span class="k">for</span> <span class="p">(;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">D</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
                <span class="kt">float</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="n">k</span><span class="p">];</span>
                <span class="n">sum</span> <span class="o">+=</span> <span class="n">diff</span> <span class="o">*</span> <span class="n">diff</span><span class="p">;</span>
            <span class="p">}</span>


	    <span class="c1">// Store result in distance matrix</span>
	    <span class="n">_mm_store_ss</span><span class="p">(</span><span class="o">&amp;</span><span class="n">distances</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">j</span><span class="p">],</span> <span class="n">_mm_sqrt_ps</span><span class="p">(</span><span class="n">temp</span><span class="p">));</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Note the differences in the generated instructions for the inner loop:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0000000000003f34	dup.2d	v1, v0[1]
0000000000003f38	fadd.4s	v0, v0, v1
0000000000003f3c	dup.4s	v1, v0[1]
0000000000003f40	movi.2d	v2, #0000000000000000 // Set v2 to 0 -&gt; _mm_setzero_ps()
0000000000003f44	mov.s	v2[0], v1[0]
0000000000003f48	fadd.4s	v0, v0, v2
0000000000003f4c	add	x17, x14, x15
0000000000003f50	fsqrt.4s	v0, v0 // Square root of the sum
0000000000003f54	str	s0, [x2, x17, lsl #2]
0000000000003f58	add	x14, x14, #0x1
0000000000003f5c	add	x16, x16, x12
0000000000003f60	cmp	x14, x13
0000000000003f64	b.eq	0x3f0c
0000000000003f68	movi.2d	v0, #0000000000000000
0000000000003f6c	cmp	w5, #0x4
0000000000003f70	b.lt	0x3f34 // Loop back
0000000000003f74	mov	x17, #0x0
0000000000003f78	mov	x3, x0
0000000000003f7c	mov	x6, x16
0000000000003f80	ldr	q1, [x3], #0x10 
0000000000003f84	ldr	q2, [x6], #0x10
0000000000003f88	fsub.4s	v1, v1, v2 // Subtract the elements -&gt; _mm_sub_ps()
0000000000003f8c	fmul.4s	v1, v1, v1 // Square the differences -&gt; _mm_mul_ps()
0000000000003f90	fadd.4s	v0, v0, v1 // Add the squared differences -&gt; _mm_add_ps()
0000000000003f94	add	x17, x17, #0x4
0000000000003f98	cmp	x17, x9
0000000000003f9c	b.le	0x3f80
0000000000003fa0	b	0x3f34
</code></pre></div></div>

<h1 id="conclusions">Conclusions</h1>

<p>Optimizing performance in Python requires an understanding of how the CPU processes instructions and accesses memory. While Python’s high-level nature makes it easy to use, it also introduces inefficiencies that can slow down execution. By applying techniques such as cache-friendly memory access, instruction-level parallelism, and SIMD vectorization, we can significantly improve performance.</p>

<p>In this post, we demonstrated how to optimize Euclidean distance calculations using:</p>

<p>Efficient memory access patterns to reduce cache misses.</p>
<ul>
  <li>Blocking techniques to improve cache locality.</li>
  <li>Loop unrolling to increase instruction-level parallelism.</li>
  <li>SIMD instructions to execute multiple operations in parallel.</li>
</ul>

<p>For high-performance applications, leveraging tools like NumPy, Numba, and C extensions can further accelerate computations. By being mindful of CPU architecture and optimizing at the hardware level, we can push Python’s performance closer to that of lower-level languages like C.</p>

<p>With the right optimizations, Python can be an excellent choice for computationally intensive tasks while maintaining its readability and ease of use.</p>

		</div>
		<div class="row">
			<footer class="zsh-footer">
			  <div class="zsh-prompt">
			    <span class="user">andre_fernandes</span>@<span class="host">127.0.0.1</span>:<span class="directory">~</span>$ 
			    <span class="zsh-input" placeholder="">
				echo "Page created at 1 April 2024"
			    </span>
			  </div>
			</footer>
		</div>
		</div>
	  </div> 



    </main>
  </body>
</html>
